"""
Code LLMì„ ì´ìš©í•œ SELECT QUERY ìƒì„± (Hybrid: OLLAMA + Claude API ì§€ì›)

LLM ëª¨ë¸ ì„ íƒ ë°©ë²•:
1. OLLAMA ì‚¬ìš©: __init__ í•¨ìˆ˜ì—ì„œ self.llm_type = "ollama" (ê¸°ë³¸ê°’)
2. Claude API ì‚¬ìš©: __init__ í•¨ìˆ˜ì—ì„œ ì£¼ì„ì„ í•´ì œí•˜ì—¬ self.llm_type = "claude" ì„¤ì •

Claude API ì‚¬ìš© ì‹œ í•„ìš”ì‚¬í•­:
- pip install anthropic
- í™˜ê²½ë³€ìˆ˜ ì„¤ì •: export ANTHROPIC_API_KEY='your-api-key'
"""
"""
DB ADDRESS
222.239.231.95 : 32000
db : llm_db_test
user : genai
password : Zx82qm730!
"""

"""
-- llm_db_test ë°ì´í„°ë² ì´ìŠ¤ìš© í…Œì´ë¸” ìƒì„± ì¿¼ë¦¬ (MariaDB)
-- 4ê°œ ì´ìƒì˜ í…Œì´ë¸” ì¡°ì¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì „ììƒê±°ë˜ ì‹œìŠ¤í…œ

USE llm_db_test;

-- 1. ì‚¬ìš©ì í…Œì´ë¸”
CREATE TABLE users (
    user_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì‚¬ìš©ì ê³ ìœ  ì‹ë³„ì',
    username VARCHAR(50) NOT NULL UNIQUE COMMENT 'ì‚¬ìš©ìëª… (ë¡œê·¸ì¸ ID)',
    email VARCHAR(100) NOT NULL UNIQUE COMMENT 'ì´ë©”ì¼ ì£¼ì†Œ',
    full_name VARCHAR(100) NOT NULL COMMENT 'ì‚¬ìš©ì ì‹¤ëª…',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ê³„ì • ìƒì„±ì¼ì‹œ',
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ë§ˆì§€ë§‰ ìˆ˜ì •ì¼ì‹œ',
    status ENUM('active', 'inactive', 'suspended') DEFAULT 'active' COMMENT 'ê³„ì • ìƒíƒœ (í™œì„±/ë¹„í™œì„±/ì •ì§€)'
) COMMENT = 'ì‚¬ìš©ì ê³„ì • ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

-- 2. ì¹´í…Œê³ ë¦¬ í…Œì´ë¸”
CREATE TABLE categories (
    category_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì¹´í…Œê³ ë¦¬ ê³ ìœ  ì‹ë³„ì',
    category_name VARCHAR(100) NOT NULL UNIQUE COMMENT 'ì¹´í…Œê³ ë¦¬ëª…',
    parent_category_id INT NULL COMMENT 'ìƒìœ„ ì¹´í…Œê³ ë¦¬ ID (ìµœìƒìœ„ëŠ” NULL)',
    description TEXT COMMENT 'ì¹´í…Œê³ ë¦¬ ì„¤ëª…',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ì¹´í…Œê³ ë¦¬ ìƒì„±ì¼ì‹œ',
    FOREIGN KEY (parent_category_id) REFERENCES categories(category_id)
) COMMENT = 'ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸” (ê³„ì¸µêµ¬ì¡° ì§€ì›)';

-- 3. ìƒí’ˆ í…Œì´ë¸”
CREATE TABLE products (
    product_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ìƒí’ˆ ê³ ìœ  ì‹ë³„ì',
    product_name VARCHAR(200) NOT NULL COMMENT 'ìƒí’ˆëª…',
    category_id INT NOT NULL COMMENT 'ì†Œì† ì¹´í…Œê³ ë¦¬ ID',
    price DECIMAL(10, 2) NOT NULL COMMENT 'ìƒí’ˆ ê°€ê²©',
    stock_quantity INT NOT NULL DEFAULT 0 COMMENT 'ì¬ê³  ìˆ˜ëŸ‰',
    description TEXT COMMENT 'ìƒí’ˆ ìƒì„¸ ì„¤ëª…',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ìƒí’ˆ ë“±ë¡ì¼ì‹œ',
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ìƒí’ˆ ì •ë³´ ìˆ˜ì •ì¼ì‹œ',
    status ENUM('active', 'inactive', 'discontinued') DEFAULT 'active' COMMENT 'ìƒí’ˆ íŒë§¤ ìƒíƒœ (íŒë§¤ì¤‘/íŒë§¤ì¤‘ì§€/ë‹¨ì¢…)',
    FOREIGN KEY (category_id) REFERENCES categories(category_id)
) COMMENT = 'íŒë§¤ ìƒí’ˆ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

-- 4. ì£¼ë¬¸ í…Œì´ë¸”
CREATE TABLE orders (
    order_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì£¼ë¬¸ ê³ ìœ  ì‹ë³„ì',
    user_id INT NOT NULL COMMENT 'ì£¼ë¬¸í•œ ì‚¬ìš©ì ID',
    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ì£¼ë¬¸ ìƒì„±ì¼ì‹œ',
    total_amount DECIMAL(10, 2) NOT NULL COMMENT 'ì£¼ë¬¸ ì´ ê¸ˆì•¡',
    status ENUM('pending', 'processing', 'shipped', 'delivered', 'cancelled') DEFAULT 'pending' COMMENT 'ì£¼ë¬¸ ì²˜ë¦¬ ìƒíƒœ',
    shipping_address TEXT NOT NULL COMMENT 'ë°°ì†¡ ì£¼ì†Œ',
    FOREIGN KEY (user_id) REFERENCES users(user_id)
) COMMENT = 'ì‚¬ìš©ì ì£¼ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

-- 5. ì£¼ë¬¸ ìƒì„¸ í…Œì´ë¸”
CREATE TABLE order_items (
    order_item_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì£¼ë¬¸ ìƒì„¸ ê³ ìœ  ì‹ë³„ì',
    order_id INT NOT NULL COMMENT 'ì£¼ë¬¸ ID',
    product_id INT NOT NULL COMMENT 'ì£¼ë¬¸ëœ ìƒí’ˆ ID',
    quantity INT NOT NULL COMMENT 'ì£¼ë¬¸ ìˆ˜ëŸ‰',
    unit_price DECIMAL(10, 2) NOT NULL COMMENT 'ì£¼ë¬¸ ë‹¹ì‹œ ìƒí’ˆ ë‹¨ê°€',
    subtotal DECIMAL(10, 2) NOT NULL COMMENT 'í•´ë‹¹ ìƒí’ˆì˜ ì£¼ë¬¸ ì†Œê³„',
    FOREIGN KEY (order_id) REFERENCES orders(order_id),
    FOREIGN KEY (product_id) REFERENCES products(product_id)
) COMMENT = 'ì£¼ë¬¸ì— í¬í•¨ëœ ê°œë³„ ìƒí’ˆ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

-- 6. ë¦¬ë·° í…Œì´ë¸”
CREATE TABLE reviews (
    review_id INT PRIMARY KEY AUTO_INCREMENT,
    user_id INT NOT NULL,
    product_id INT NOT NULL,
    order_id INT NOT NULL,
    rating INT NOT NULL CHECK (rating >= 1 AND rating <= 5),
    review_text TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(user_id),
    FOREIGN KEY (product_id) REFERENCES products(product_id),
    FOREIGN KEY (order_id) REFERENCES orders(order_id)
);
"""

import pymysql
import requests
import json
import sys
import re
import os
from typing import List, Dict, Any, Optional, Tuple
from neo4j import GraphDatabase
from dataclasses import dataclass

# Claude API ì‚¬ìš©ì„ ìœ„í•œ import (ì„¤ì¹˜ í•„ìš”: pip install anthropic)
try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

@dataclass
class TableRelation:
    """í…Œì´ë¸” ê°„ ê´€ê³„ ì •ë³´"""
    from_table: str
    from_column: str
    to_table: str
    to_column: str
    relation_type: str  # 'foreign_key', 'semantic', 'naming_pattern'
    confidence: float   # ê´€ê³„ì˜ í™•ì‹ ë„ (0.0 ~ 1.0)

@dataclass
class TableSchema:
    """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´"""
    table_name: str
    columns: List[Dict[str, Any]]
    primary_keys: List[str]
    foreign_keys: List[Dict[str, str]]
    comment: str

class HybridQueryGenerator:
    def __init__(self):
        # MariaDB ì—°ê²° ì •ë³´ (Docker ì»¨í…Œì´ë„ˆ ì‚¬ìš©ì‹œ)
        self.db_config = {
            'host': 'localhost',  # Docker: localhost, ì™¸ë¶€ì„œë²„: 222.239.231.95
            'port': 32000,
            'user': 'genai',
            'password': 'genai1234',
            'database': 'llm_db_test',
            'charset': 'utf8mb4'
        }
        
        # Neo4j ì—°ê²° ì •ë³´
        self.neo4j_config = {
            'uri': 'bolt://localhost:7687',
            'username': 'neo4j',
            'password': 'password123'
        }
        
        # LLM ëª¨ë¸ ì„¤ì • - ì›í•˜ëŠ” ëª¨ë¸ì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”
        # =================================================================
        
        on_local = True
        if on_local:
            self.llm_type = "ollama"
            self.ollama_url = "http://localhost:11434"
            self.model_name = "codellama:7b"  # 4GB ë©”ëª¨ë¦¬ì— ì í•©í•˜ê³  í•œê¸€ ì§€ì› ìš°ìˆ˜ (ë¹ ë¦„)
        else:
            self.llm_type = "claude"
            self.claude_model = "claude-3-5-sonnet-20241022"  # ìµœì‹  Claude ëª¨ë¸
            self.claude_api_key = os.getenv('ANTHROPIC_API_KEY', "")  # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°

        
        self.connection = None
        self.neo4j_driver = None
        self.tables_info = {}
        self.table_schemas = {}
        self.table_relations = []
        
        # Claude í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        if self.llm_type == "claude":
            if not ANTHROPIC_AVAILABLE:
                print("âŒ anthropic ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ì„¤ì¹˜ ëª…ë ¹: pip install anthropic")
                self.llm_type = "ollama"  # í´ë°±
            elif not hasattr(self, 'claude_api_key') or not self.claude_api_key:
                print("âš ï¸  ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                print("ğŸ’¡ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
                print("   1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •: export ANTHROPIC_API_KEY='your-key'")
                print("   2. ì½”ë“œì—ì„œ ì§ì ‘ ì„¤ì •: self.claude_api_key = 'your-key'")
                print("   3. OLLAMA ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½")
                self.llm_type = "ollama"  # í´ë°±
            else:
                try:
                    self.claude_client = anthropic.Anthropic(api_key=self.claude_api_key)
                    print(f"âœ… Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ: {self.claude_model}")
                except Exception as e:
                    print(f"âŒ Claude API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                    self.llm_type = "ollama"  # í´ë°±
    
    def connect_to_database(self) -> bool:
        """MariaDBì— ì—°ê²°"""
        try:
            self.connection = pymysql.connect(**self.db_config)
            print("âœ… MariaDB ì—°ê²° ì„±ê³µ!")
            return True
        except Exception as e:
            print(f"âŒ MariaDB ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
    
    def disconnect_from_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ"""
        if self.connection:
            self.connection.close()
            print("ğŸ”Œ MariaDB ì—°ê²° ì¢…ë£Œ")
        
        if self.neo4j_driver:
            self.neo4j_driver.close()
            print("ğŸ”Œ Neo4j ì—°ê²° ì¢…ë£Œ")
    
    def connect_to_neo4j(self) -> bool:
        """Neo4jì— ì—°ê²°"""
        try:
            self.neo4j_driver = GraphDatabase.driver(
                self.neo4j_config['uri'],
                auth=(self.neo4j_config['username'], self.neo4j_config['password'])
            )
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            with self.neo4j_driver.session() as session:
                result = session.run("RETURN 1 as test")
                result.single()
            print("âœ… Neo4j ì—°ê²° ì„±ê³µ!")
            return True
        except Exception as e:
            print(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ Neo4jê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: docker-compose up -d neo4j")
            return False
    
    def check_ollama_connection(self) -> bool:
        """OLLAMA ì„œë²„ ì—°ê²° í™•ì¸"""
        if self.llm_type != "ollama":
            return True  # OLLAMA ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ìŠ¤í‚µ
            
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                print("âœ… OLLAMA ì„œë²„ ì—°ê²° ì„±ê³µ!")
                return True
            else:
                print("âŒ OLLAMA ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜")
                return False
        except Exception as e:
            print(f"âŒ OLLAMA ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ OLLAMAê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: ollama serve")
            return False
    
    def check_model_availability(self) -> bool:
        """ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸"""
        if self.llm_type == "claude":
            # Claude APIì˜ ê²½ìš° API í‚¤ë§Œ í™•ì¸
            return hasattr(self, 'claude_client')
        
        # OLLAMA ëª¨ë¸ í™•ì¸
        try:
            response = requests.get(f"{self.ollama_url}/api/tags")
            if response.status_code == 200:
                models = response.json().get('models', [])
                available_models = [model['name'] for model in models]
                
                if self.model_name in available_models:
                    print(f"âœ… ëª¨ë¸ '{self.model_name}' ì‚¬ìš© ê°€ëŠ¥!")
                    return True
                else:
                    print(f"âŒ ëª¨ë¸ '{self.model_name}'ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤:")
                    for model in available_models:
                        print(f"  - {model}")
                    
                    # 4GB ë©”ëª¨ë¦¬ì— ì í•©í•œ ë‹¤ë¥¸ ëª¨ë¸ ì¶”ì²œ (í•œê¸€ ì§€ì› ìˆœì„œ)
                    recommended_models = [
                        ("deepseek-coder:1.3b", "í•œê¸€ ì§€ì› ìš°ìˆ˜, ë©”ëª¨ë¦¬ ì ˆì•½"),
                        ("deepseek-coder:6.7b", "í•œê¸€ ì§€ì› ìš°ìˆ˜, ì„±ëŠ¥ ìµœê³ "),
                        ("codellama:7b-code", "ë‹¤êµ­ì–´ ì§€ì›, ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©"),
                        ("starcoder:3b", "ì˜ì–´ íŠ¹í™”, í•œê¸€ ì œí•œì "),
                        ("sqlcoder:7b", "SQL íŠ¹í™”, ì˜ì–´ ìœ„ì£¼")
                    ]
                    
                    print("\nğŸ’¡ 4GB ë©”ëª¨ë¦¬ì— ì¶”ì²œë˜ëŠ” ëª¨ë¸ë“¤ (í•œê¸€ ì§€ì› ìˆœì„œ):")
                    for model, desc in recommended_models:
                        print(f"  ollama pull {model}  # {desc}")
                    
                    return False
            return False
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")
            return False
    
    def call_claude_api(self, prompt: str) -> Optional[str]:
        """Claude API í˜¸ì¶œ"""
        try:
            print(f"ğŸ¤– Claude API í˜¸ì¶œ: {self.claude_model}")
            
            message = self.claude_client.messages.create(
                model=self.claude_model,
                max_tokens=1000,
                temperature=0.1,  # ì •í™•í•œ SQL ìƒì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            return message.content[0].text.strip()
            
        except Exception as e:
            print(f"âŒ Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def call_ollama_api(self, prompt: str) -> Optional[str]:
        """OLLAMA API í˜¸ì¶œ"""
        try:
            print(f"ğŸ¤– OLLAMA í˜¸ì¶œ: {self.model_name}")
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,  # ì •í™•í•œ SQL ìƒì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                    "top_p": 0.9,
                    "num_predict": 500
                }
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate",
                json=payload,
                timeout=120  # íƒ€ì„ì•„ì›ƒì„ 120ì´ˆë¡œ ì¦ê°€ (í° ëª¨ë¸ìš©)
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '').strip()
            else:
                print(f"âŒ OLLAMA í˜¸ì¶œ ì‹¤íŒ¨: HTTP {response.status_code}")
                return None
                
        except Exception as e:
            print(f"âŒ OLLAMA í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def call_llm(self, prompt: str) -> Optional[str]:
        """LLM í˜¸ì¶œ - ì„¤ì •ëœ ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ë¶„ê¸°"""
        if self.llm_type == "claude":
            return self.call_claude_api(prompt)
        elif self.llm_type == "ollama":
            return self.call_ollama_api(prompt)
        else:
            print(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” LLM íƒ€ì…: {self.llm_type}")
            return None
    
    def get_all_tables(self) -> List[str]:
        """ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸” ì¡°íšŒ"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute("SHOW TABLES")
                tables = [table[0] for table in cursor.fetchall()]
                print(f"ğŸ“Š ë°œê²¬ëœ í…Œì´ë¸”: {len(tables)}ê°œ")
                for table in tables:
                    print(f"  - {table}")
                return tables
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_table_structure(self, table_name: str) -> Dict[str, Any]:
        """íŠ¹ì • í…Œì´ë¸”ì˜ êµ¬ì¡° ì •ë³´ ì¡°íšŒ"""
        try:
            with self.connection.cursor() as cursor:
                # í…Œì´ë¸” êµ¬ì¡° ì¡°íšŒ
                cursor.execute(f"DESCRIBE {table_name}")
                columns = cursor.fetchall()
                
                # ìƒ˜í”Œ ë°ì´í„° ì¡°íšŒ (ìµœëŒ€ 3ê°œ)
                cursor.execute(f"SELECT * FROM {table_name} LIMIT 3")
                sample_data = cursor.fetchall()
                
                structure = {
                    'columns': columns,
                    'sample_data': sample_data
                }
                
                return structure
        except Exception as e:
            print(f"âŒ í…Œì´ë¸” '{table_name}' êµ¬ì¡° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def analyze_all_tables(self) -> Dict[str, Dict]:
        """ëª¨ë“  í…Œì´ë¸” ë¶„ì„"""
        tables = self.get_all_tables()
        
        print("\nğŸ” í…Œì´ë¸” êµ¬ì¡° ë¶„ì„ ì¤‘...")
        for table in tables:
            print(f"\nğŸ“‹ í…Œì´ë¸”: {table}")
            structure = self.get_table_structure(table)
            
            if structure:
                self.tables_info[table] = structure
                
                print("  ì»¬ëŸ¼ ì •ë³´:")
                for col in structure['columns']:
                    print(f"    - {col[0]} ({col[1]})")
                
                if structure['sample_data']:
                    print("  ìƒ˜í”Œ ë°ì´í„°:")
                    for i, row in enumerate(structure['sample_data'], 1):
                        print(f"    {i}: {row}")
        
        return self.tables_info
    
    def extract_schema_from_ddl(self) -> Dict[str, TableSchema]:
        """DDL ì£¼ì„ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ"""
        # íŒŒì¼ì˜ DDL ì£¼ì„ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ì¶”ì¶œ
        ddl_content = '''
        -- 1. ì‚¬ìš©ì í…Œì´ë¸”
        CREATE TABLE users (
            user_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì‚¬ìš©ì ê³ ìœ  ì‹ë³„ì',
            username VARCHAR(50) NOT NULL UNIQUE COMMENT 'ì‚¬ìš©ìëª… (ë¡œê·¸ì¸ ID)',
            email VARCHAR(100) NOT NULL UNIQUE COMMENT 'ì´ë©”ì¼ ì£¼ì†Œ',
            full_name VARCHAR(100) NOT NULL COMMENT 'ì‚¬ìš©ì ì‹¤ëª…',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ê³„ì • ìƒì„±ì¼ì‹œ',
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ë§ˆì§€ë§‰ ìˆ˜ì •ì¼ì‹œ',
            status ENUM('active', 'inactive', 'suspended') DEFAULT 'active' COMMENT 'ê³„ì • ìƒíƒœ'
        ) COMMENT = 'ì‚¬ìš©ì ê³„ì • ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

        -- 2. ì¹´í…Œê³ ë¦¬ í…Œì´ë¸”
        CREATE TABLE categories (
            category_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì¹´í…Œê³ ë¦¬ ê³ ìœ  ì‹ë³„ì',
            category_name VARCHAR(100) NOT NULL UNIQUE COMMENT 'ì¹´í…Œê³ ë¦¬ëª…',
            parent_category_id INT NULL COMMENT 'ìƒìœ„ ì¹´í…Œê³ ë¦¬ ID (ìµœìƒìœ„ëŠ” NULL)',
            description TEXT COMMENT 'ì¹´í…Œê³ ë¦¬ ì„¤ëª…',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ì¹´í…Œê³ ë¦¬ ìƒì„±ì¼ì‹œ',
            FOREIGN KEY (parent_category_id) REFERENCES categories(category_id)
        ) COMMENT = 'ìƒí’ˆ ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸” (ê³„ì¸µêµ¬ì¡° ì§€ì›)';

        -- 3. ìƒí’ˆ í…Œì´ë¸”
        CREATE TABLE products (
            product_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ìƒí’ˆ ê³ ìœ  ì‹ë³„ì',
            product_name VARCHAR(200) NOT NULL COMMENT 'ìƒí’ˆëª…',
            category_id INT NOT NULL COMMENT 'ì†Œì† ì¹´í…Œê³ ë¦¬ ID',
            price DECIMAL(10, 2) NOT NULL COMMENT 'ìƒí’ˆ ê°€ê²©',
            stock_quantity INT NOT NULL DEFAULT 0 COMMENT 'ì¬ê³  ìˆ˜ëŸ‰',
            description TEXT COMMENT 'ìƒí’ˆ ìƒì„¸ ì„¤ëª…',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ìƒí’ˆ ë“±ë¡ì¼ì‹œ',
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'ìƒí’ˆ ì •ë³´ ìˆ˜ì •ì¼ì‹œ',
            status ENUM('active', 'inactive', 'discontinued') DEFAULT 'active' COMMENT 'ìƒí’ˆ íŒë§¤ ìƒíƒœ',
            FOREIGN KEY (category_id) REFERENCES categories(category_id)
        ) COMMENT = 'íŒë§¤ ìƒí’ˆ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

        -- 4. ì£¼ë¬¸ í…Œì´ë¸”
        CREATE TABLE orders (
            order_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì£¼ë¬¸ ê³ ìœ  ì‹ë³„ì',
            user_id INT NOT NULL COMMENT 'ì£¼ë¬¸í•œ ì‚¬ìš©ì ID',
            order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'ì£¼ë¬¸ ìƒì„±ì¼ì‹œ',
            total_amount DECIMAL(10, 2) NOT NULL COMMENT 'ì£¼ë¬¸ ì´ ê¸ˆì•¡',
            status ENUM('pending', 'processing', 'shipped', 'delivered', 'cancelled') DEFAULT 'pending' COMMENT 'ì£¼ë¬¸ ì²˜ë¦¬ ìƒíƒœ',
            shipping_address TEXT NOT NULL COMMENT 'ë°°ì†¡ ì£¼ì†Œ',
            FOREIGN KEY (user_id) REFERENCES users(user_id)
        ) COMMENT = 'ì‚¬ìš©ì ì£¼ë¬¸ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

        -- 5. ì£¼ë¬¸ ìƒì„¸ í…Œì´ë¸”
        CREATE TABLE order_items (
            order_item_id INT PRIMARY KEY AUTO_INCREMENT COMMENT 'ì£¼ë¬¸ ìƒì„¸ ê³ ìœ  ì‹ë³„ì',
            order_id INT NOT NULL COMMENT 'ì£¼ë¬¸ ID',
            product_id INT NOT NULL COMMENT 'ì£¼ë¬¸ëœ ìƒí’ˆ ID',
            quantity INT NOT NULL COMMENT 'ì£¼ë¬¸ ìˆ˜ëŸ‰',
            unit_price DECIMAL(10, 2) NOT NULL COMMENT 'ì£¼ë¬¸ ë‹¹ì‹œ ìƒí’ˆ ë‹¨ê°€',
            subtotal DECIMAL(10, 2) NOT NULL COMMENT 'í•´ë‹¹ ìƒí’ˆì˜ ì£¼ë¬¸ ì†Œê³„',
            FOREIGN KEY (order_id) REFERENCES orders(order_id),
            FOREIGN KEY (product_id) REFERENCES products(product_id)
        ) COMMENT = 'ì£¼ë¬¸ì— í¬í•¨ëœ ê°œë³„ ìƒí’ˆ ì •ë³´ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”';

        -- 6. ë¦¬ë·° í…Œì´ë¸”
        CREATE TABLE reviews (
            review_id INT PRIMARY KEY AUTO_INCREMENT,
            user_id INT NOT NULL,
            product_id INT NOT NULL,
            order_id INT NOT NULL,
            rating INT NOT NULL CHECK (rating >= 1 AND rating <= 5),
            review_text TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users(user_id),
            FOREIGN KEY (product_id) REFERENCES products(product_id),
            FOREIGN KEY (order_id) REFERENCES orders(order_id)
        );
        '''
        
        schemas = {}
        
        # ê°„ë‹¨í•œ DDL íŒŒì‹± (ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” ë” ì •êµí•œ íŒŒì„œ í•„ìš”)
        table_patterns = re.findall(
            r'CREATE TABLE (\w+) \((.*?)\) COMMENT = \'(.*?)\';',
            ddl_content,
            re.DOTALL | re.IGNORECASE
        )
        
        for table_name, columns_str, comment in table_patterns:
            # ì»¬ëŸ¼ ì •ë³´ ì¶”ì¶œ
            columns = []
            primary_keys = []
            foreign_keys = []
            
            lines = columns_str.strip().split('\n')
            for line in lines:
                line = line.strip().strip(',')
                
                if 'PRIMARY KEY' in line and not line.startswith('FOREIGN KEY'):
                    # PRIMARY KEY ì¶”ì¶œ
                    if 'AUTO_INCREMENT' in line:
                        col_name = line.split()[0]
                        primary_keys.append(col_name)
                        columns.append({
                            'name': col_name,
                            'type': 'INT',
                            'nullable': False,
                            'auto_increment': True
                        })
                elif line.startswith('FOREIGN KEY'):
                    # FOREIGN KEY ì¶”ì¶œ
                    fk_match = re.search(r'FOREIGN KEY \((\w+)\) REFERENCES (\w+)\((\w+)\)', line)
                    if fk_match:
                        from_col, to_table, to_col = fk_match.groups()
                        foreign_keys.append({
                            'from_column': from_col,
                            'to_table': to_table,
                            'to_column': to_col
                        })
                elif line and not line.startswith('FOREIGN KEY') and not line.startswith('CONSTRAINT'):
                    # ì¼ë°˜ ì»¬ëŸ¼
                    parts = line.split()
                    if len(parts) >= 2:
                        col_name = parts[0]
                        col_type = parts[1]
                        nullable = 'NOT NULL' not in line
                        
                        if col_name not in [pk for pk in primary_keys]:
                            columns.append({
                                'name': col_name,
                                'type': col_type,
                                'nullable': nullable,
                                'auto_increment': False
                            })
            
            schemas[table_name] = TableSchema(
                table_name=table_name,
                columns=columns,
                primary_keys=primary_keys,
                foreign_keys=foreign_keys,
                comment=comment
            )
        
        self.table_schemas = schemas
        print(f"ğŸ“Š ìŠ¤í‚¤ë§ˆ ë¶„ì„ ì™„ë£Œ: {len(schemas)}ê°œ í…Œì´ë¸”")
        return schemas
    
    def extract_table_relations(self) -> List[TableRelation]:
        """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ ë©”íƒ€ë°ì´í„°ì™€ ë°ì´í„° ë¶„ì„ì„ í†µí•œ í…Œì´ë¸” ê°„ ê´€ê³„ ì¶”ì¶œ"""
        relations = []
        
        print("ğŸ”— ì‹¤ì œ DB ë©”íƒ€ë°ì´í„°ì—ì„œ í…Œì´ë¸” ê´€ê³„ ì¶”ì¶œ ì¤‘...")
        
        # 1. ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì˜ Foreign Key ì œì•½ì¡°ê±´ ì¡°íšŒ
        relations.extend(self._extract_real_foreign_keys())
        
        # 2. ë°ì´í„° ê°’ ë¶„ì„ ê¸°ë°˜ ê´€ê³„ ì¶”ì • (ì—°ê²° í™•ì¸ì´ ê°€ëŠ¥í•œ ê²½ìš°)
        if self.connection:
            relations.extend(self._extract_data_based_relations())
        
        # ì¤‘ë³µ ì œê±°
        unique_relations = []
        seen = set()
        for rel in relations:
            key = (rel.from_table, rel.from_column, rel.to_table, rel.to_column)
            if key not in seen:
                unique_relations.append(rel)
                seen.add(key)
        
        self.table_relations = unique_relations
        print(f"ğŸ”— ê´€ê³„ ì¶”ì¶œ ì™„ë£Œ: {len(unique_relations)}ê°œ ê´€ê³„")
        
        for rel in unique_relations:
            print(f"  {rel.from_table}.{rel.from_column} â†’ {rel.to_table}.{rel.to_column} ({rel.relation_type}, {rel.confidence:.2f})")
        
        return unique_relations
    
    def _extract_real_foreign_keys(self) -> List[TableRelation]:
        """ì‹¤ì œ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ Foreign Key ì œì•½ì¡°ê±´ ì¡°íšŒ"""
        relations = []
        
        if not self.connection:
            print("âš ï¸ DB ì—°ê²° ì—†ìŒ, FK ì œì•½ì¡°ê±´ ì¡°íšŒ ìŠ¤í‚µ")
            return relations
        
        try:
            with self.connection.cursor() as cursor:
                # MariaDB/MySQLì—ì„œ FK ì œì•½ì¡°ê±´ ì¡°íšŒ
                fk_query = """
                SELECT 
                    kcu.TABLE_NAME as from_table,
                    kcu.COLUMN_NAME as from_column,
                    kcu.REFERENCED_TABLE_NAME as to_table,
                    kcu.REFERENCED_COLUMN_NAME as to_column,
                    kcu.CONSTRAINT_NAME as constraint_name
                FROM information_schema.KEY_COLUMN_USAGE kcu
                WHERE kcu.TABLE_SCHEMA = %s 
                  AND kcu.REFERENCED_TABLE_NAME IS NOT NULL
                ORDER BY kcu.TABLE_NAME, kcu.COLUMN_NAME
                """
                
                cursor.execute(fk_query, (self.db_config['database'],))
                fk_results = cursor.fetchall()
                
                for row in fk_results:
                    from_table, from_column, to_table, to_column, constraint_name = row
                    relations.append(TableRelation(
                        from_table=from_table,
                        from_column=from_column,
                        to_table=to_table,
                        to_column=to_column,
                        relation_type='foreign_key',
                        confidence=1.0
                    ))
                    print(f"ğŸ”‘ ì‹¤ì œ FK ë°œê²¬: {from_table}.{from_column} â†’ {to_table}.{to_column}")
                
        except Exception as e:
            print(f"âš ï¸ FK ì œì•½ì¡°ê±´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        return relations
    

    
    def _extract_data_based_relations(self) -> List[TableRelation]:
        """ì‹¤ì œ ë°ì´í„° ê°’ ë¶„ì„ìœ¼ë¡œ ê´€ê³„ ì¶”ì •"""
        relations = []
        
        print("ğŸ“Š ë°ì´í„° ê°’ ë¶„ì„ìœ¼ë¡œ ê´€ê³„ ì¶”ì • ì¤‘...")
        
        try:
            table_names = list(self.table_schemas.keys())
            
            with self.connection.cursor() as cursor:
                for table1_name in table_names:
                    schema1 = self.table_schemas[table1_name]
                    
                    for col1 in schema1.columns:
                        if 'id' in col1['name'].lower() and col1['name'] != f"{table1_name}_id":
                            # ì´ ì»¬ëŸ¼ì˜ ê°’ë“¤ì´ ë‹¤ë¥¸ í…Œì´ë¸”ì˜ PKì™€ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                            
                            for table2_name in table_names:
                                if table1_name == table2_name:
                                    continue
                                    
                                schema2 = self.table_schemas[table2_name]
                                pk_columns = schema2.primary_keys
                                
                                if not pk_columns:
                                    continue
                                
                                pk_col = pk_columns[0]  # ì²« ë²ˆì§¸ PK ì‚¬ìš©
                                
                                # ì‹¤ì œ ë°ì´í„° ê°’ ë¹„êµ (ìƒ˜í”Œë§)
                                try:
                                    # table1ì˜ ì»¬ëŸ¼ ê°’ë“¤
                                    cursor.execute(f"""
                                        SELECT DISTINCT {col1['name']} 
                                        FROM {table1_name} 
                                        WHERE {col1['name']} IS NOT NULL 
                                        LIMIT 20
                                    """)
                                    values1 = [row[0] for row in cursor.fetchall()]
                                    
                                    if not values1:
                                        continue
                                    
                                    # table2ì˜ PK ê°’ë“¤
                                    cursor.execute(f"""
                                        SELECT DISTINCT {pk_col} 
                                        FROM {table2_name} 
                                        WHERE {pk_col} IS NOT NULL 
                                        LIMIT 50
                                    """)
                                    values2 = [row[0] for row in cursor.fetchall()]
                                    
                                    if not values2:
                                        continue
                                    
                                    # êµì§‘í•© ë¹„ìœ¨ ê³„ì‚°
                                    intersection = set(values1) & set(values2)
                                    if len(intersection) > 0:
                                        match_ratio = len(intersection) / len(values1)
                                        
                                        if match_ratio > 0.5:  # 50% ì´ìƒ ì¼ì¹˜
                                            confidence = min(0.9, 0.5 + match_ratio * 0.4)
                                            relations.append(TableRelation(
                                                from_table=table1_name,
                                                from_column=col1['name'],
                                                to_table=table2_name,
                                                to_column=pk_col,
                                                relation_type='data_analysis',
                                                confidence=confidence
                                            ))
                                            print(f"ğŸ“ˆ ë°ì´í„° ê¸°ë°˜ ê´€ê³„ ë°œê²¬: {table1_name}.{col1['name']} â†’ {table2_name}.{pk_col} (ì¼ì¹˜ìœ¨: {match_ratio:.2f})")
                                
                                except Exception as e:
                                    # ê°œë³„ í…Œì´ë¸” ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì†
                                    pass
                
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ê¸°ë°˜ ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {e}")
        
        return relations
    
    def create_schema_graph_in_neo4j(self):
        """Neo4jì— ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ìƒì„±"""
        if not self.neo4j_driver:
            print("âŒ Neo4j ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        print("ğŸ”„ Neo4jì— ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ìƒì„± ì¤‘...")
        
        with self.neo4j_driver.session() as session:
            # ê¸°ì¡´ ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ì‚­ì œ
            session.run("MATCH (n:Table)-[r]-(m) DELETE r")
            session.run("MATCH (n:Table) DELETE n")
            session.run("MATCH (n:Column) DELETE n")
            
            # í…Œì´ë¸” ë…¸ë“œ ìƒì„±
            for table_name, schema in self.table_schemas.items():
                session.run("""
                    CREATE (t:Table {
                        name: $table_name,
                        comment: $comment,
                        primary_keys: $primary_keys,
                        table_type: 'main'
                    })
                """, table_name=table_name, comment=schema.comment, 
                primary_keys=schema.primary_keys)
                
                # ì»¬ëŸ¼ ë…¸ë“œ ìƒì„± ë° í…Œì´ë¸”ê³¼ ì—°ê²°
                for col in schema.columns:
                    session.run("""
                        MATCH (t:Table {name: $table_name})
                        CREATE (c:Column {
                            name: $col_name,
                            type: $col_type,
                            nullable: $nullable,
                            auto_increment: $auto_increment
                        })
                        CREATE (t)-[:HAS_COLUMN]->(c)
                    """, table_name=table_name, col_name=col['name'], 
                    col_type=col['type'], nullable=col['nullable'],
                    auto_increment=col.get('auto_increment', False))
            
            # ê´€ê³„ ìƒì„±
            for rel in self.table_relations:
                session.run("""
                    MATCH (from_table:Table {name: $from_table})
                    MATCH (to_table:Table {name: $to_table})
                    CREATE (from_table)-[:REFERENCES {
                        from_column: $from_column,
                        to_column: $to_column,
                        relation_type: $relation_type,
                        confidence: $confidence
                    }]->(to_table)
                """, from_table=rel.from_table, to_table=rel.to_table,
                from_column=rel.from_column, to_column=rel.to_column,
                relation_type=rel.relation_type, confidence=rel.confidence)
        
        print("âœ… Neo4j ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")
    
    def query_relationship_paths(self, start_table: str, end_table: str = None, max_depth: int = 3) -> List[Dict]:
        """Neo4jì—ì„œ í…Œì´ë¸” ê°„ ê´€ê³„ ê²½ë¡œ ì¡°íšŒ"""
        if not self.neo4j_driver:
            print("âŒ Neo4j ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return []
        
        with self.neo4j_driver.session() as session:
            if end_table:
                # íŠ¹ì • í…Œì´ë¸” ê°„ ê²½ë¡œ ì°¾ê¸°
                query = """
                MATCH path = (start:Table {name: $start_table})-[:REFERENCES*1..{max_depth}]-(end:Table {name: $end_table})
                RETURN path, length(path) as path_length
                ORDER BY path_length
                LIMIT 10
                """.format(max_depth=max_depth)
                
                result = session.run(query, start_table=start_table, end_table=end_table)
            else:
                # ì‹œì‘ í…Œì´ë¸”ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•œ ëª¨ë“  í…Œì´ë¸”
                query = """
                MATCH path = (start:Table {name: $start_table})-[:REFERENCES*1..{max_depth}]-(other:Table)
                WHERE start <> other
                RETURN path, other.name as connected_table, length(path) as path_length
                ORDER BY path_length, other.name
                """.format(max_depth=max_depth)
                
                result = session.run(query, start_table=start_table)
            
            paths = []
            for record in result:
                path_info = {
                    'path': record['path'],
                    'length': record['path_length']
                }
                if end_table:
                    path_info['target'] = end_table
                else:
                    path_info['target'] = record['connected_table']
                
                paths.append(path_info)
            
            return paths
    
    def search_tables_with_graph_metadata(self, user_request: str) -> List[str]:
        """Neo4j ê·¸ë˜í”„ ë©”íƒ€ ì •ë³´ë¥¼ í™œìš©í•œ ìˆœìˆ˜ ê·¸ë˜í”„ ê¸°ë°˜ í…Œì´ë¸” ê²€ìƒ‰"""
        if not self.neo4j_driver:
            print("âŒ Neo4j ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤. í‚¤ì›Œë“œ ë°©ì‹ìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
            return self.extract_relevant_tables_fallback(user_request)
        
        print("ğŸ” Neo4j ê·¸ë˜í”„ ë©”íƒ€ ì •ë³´ë¡œ ì˜ë¯¸ì  í…Œì´ë¸” ê²€ìƒ‰ ì¤‘...")
        
        with self.neo4j_driver.session() as session:
            # 1ë‹¨ê³„: ì»¬ëŸ¼ ë¶„ì„ ê¸°ë°˜ ê°•í™”ëœ í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
            print("ğŸ§  ì»¬ëŸ¼ ë¶„ì„ê³¼ LLMì„ í™œìš©í•œ ì§€ëŠ¥ì  í…Œì´ë¸” ê²€ìƒ‰ ì¤‘...")
            
            # ëª¨ë“  í…Œì´ë¸”ê³¼ ê°•í™”ëœ ë©”íƒ€ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ì»¬ëŸ¼ëª… + ë°ì´í„°ê°’ ë¶„ì„ í¬í•¨)
            enhanced_tables_query = """
            MATCH (t:Table)
            RETURN t.name as table_name, 
                   t.comment as comment,
                   coalesce(t.estimated_role, '') as estimated_role,
                   coalesce(t.table_type, '') as table_type,
                   coalesce(t.business_purpose, '') as business_purpose,
                   coalesce(t.confidence_score, 0.0) as confidence_score,
                   coalesce(t.data_estimated_role, '') as data_estimated_role,
                   coalesce(t.data_confidence_score, 0.0) as data_confidence_score,
                   coalesce(t.enhanced_comment, t.comment) as enhanced_comment,
                   coalesce(t.total_rows, 0) as total_rows
            ORDER BY t.name
            """
            
            all_tables = session.run(enhanced_tables_query)
            table_info = []
            for record in all_tables:
                # ë¶„ì„ ì •ë³´ í†µí•© (ì»¬ëŸ¼ëª… ë¶„ì„ + ë°ì´í„°ê°’ ë¶„ì„)
                table_name = record['table_name']
                estimated_role = record['estimated_role']
                data_estimated_role = record['data_estimated_role']
                enhanced_comment = record['enhanced_comment']
                total_rows = record['total_rows']
                
                # ìµœì¢… ì—­í• ê³¼ ì„¤ëª… ê²°ì •
                final_role = ""
                final_description = enhanced_comment or record['comment']
                
                if data_estimated_role and record['data_confidence_score'] > 0.3:
                    # ë°ì´í„° ë¶„ì„ ê²°ê³¼ê°€ ì‹ ë¢°ë„ê°€ ë†’ìœ¼ë©´ ìš°ì„  ì‚¬ìš©
                    final_role = data_estimated_role
                    if estimated_role and estimated_role != data_estimated_role:
                        final_role += f" (ì»¬ëŸ¼ë¶„ì„: {estimated_role})"
                elif estimated_role:
                    # ì»¬ëŸ¼ëª… ë¶„ì„ ê²°ê³¼ ì‚¬ìš©
                    final_role = estimated_role
                
                business_purpose = record['business_purpose'] or final_description
                
                table_info.append({
                    'name': table_name,
                    'description': final_description,
                    'estimated_role': final_role,
                    'table_type': record['table_type'],
                    'business_purpose': business_purpose,
                    'confidence_score': max(record['confidence_score'], record['data_confidence_score']),
                    'total_rows': total_rows
                })
            
            # LLMì—ê²Œ ê°•í™”ëœ ë©”íƒ€ë°ì´í„°ë¡œ ì˜ë¯¸ì  ë¶„ì„ ìš”ì²­
            table_descriptions = "\n".join([
                f"- {table['name']}: {table['description']}"
                + (f" [ì¶”ì •ì—­í• : {table['estimated_role']}]" if table['estimated_role'] else "")
                + (f" [ë ˆì½”ë“œìˆ˜: {table['total_rows']}ê°œ]" if table['total_rows'] > 0 else "")
                + (f" [ì‹ ë¢°ë„: {table['confidence_score']:.2f}]" if table['confidence_score'] > 0 else "")
                for table in table_info
            ])
            
            # LLM íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
            if self.llm_type == "claude":
                prompt = f"""ë‹¤ìŒì€ ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  í…Œì´ë¸”ê³¼ ì„¤ëª…ì…ë‹ˆë‹¤:

{table_descriptions}

ì‚¬ìš©ì ìš”ì²­: "{user_request}"

ìœ„ì˜ í…Œì´ë¸” ì„¤ëª…ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ”ë° í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ì˜ë¯¸ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì„ íƒí•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
1. ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì •ë³´ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í…Œì´ë¸”
2. ë°ì´í„°ë¥¼ ì¡°ì¸í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì¤‘ê°„ í…Œì´ë¸”
3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ìƒ í•¨ê»˜ ì¡°íšŒë˜ì–´ì•¼ í•˜ëŠ” í…Œì´ë¸”

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{"selected_tables": ["table1", "table2"], "reasoning": "ì„ íƒ ì´ìœ ë¥¼ ì„¤ëª…"}}"""
            else:
                prompt = f"""ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´:
{table_descriptions}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ í…Œì´ë¸”ë“¤ ì¤‘ì—ì„œ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ”ë° í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ì„ íƒí•˜ì—¬ JSONìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.

JSON í˜•ì‹:
{{"selected_tables": ["í…Œì´ë¸”ëª…1", "í…Œì´ë¸”ëª…2"], "reasoning": "ì„ íƒ ì´ìœ "}}

JSON:"""
            
            # LLM í˜¸ì¶œ
            llm_response = self.call_llm(prompt)
            selected_tables = []
            
            if llm_response:
                try:
                    # JSON íŒŒì‹±
                    import json
                    response_clean = llm_response.strip()
                    
                    # JSON ë¸”ë¡ ì°¾ê¸°
                    json_start = response_clean.find('{')
                    json_end = response_clean.rfind('}') + 1
                    
                    if json_start >= 0 and json_end > json_start:
                        json_str = response_clean[json_start:json_end]
                        result = json.loads(json_str)
                        
                        if 'selected_tables' in result:
                            selected_tables = result['selected_tables']
                            reasoning = result.get('reasoning', '')
                            
                            print(f"ğŸ¯ LLM ì„ íƒ ê²°ê³¼: {selected_tables}")
                            print(f"ğŸ“ ì„ íƒ ì´ìœ : {reasoning}")
                            
                except (json.JSONDecodeError, Exception) as e:
                    print(f"âš ï¸ LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
                    selected_tables = []
            
            # 2ë‹¨ê³„: ê·¸ë˜í”„ ê¸°ë°˜ ì—°ê´€ í…Œì´ë¸” í™•ì¥
            if selected_tables:
                print("ğŸ”— ê·¸ë˜í”„ì—ì„œ ì—°ê´€ í…Œì´ë¸” ìë™ í™•ì¥ ì¤‘...")
                
                # ì„ íƒëœ í…Œì´ë¸”ë“¤ê³¼ ì—°ê²°ëœ í…Œì´ë¸” ì°¾ê¸°
                expand_query = """
                MATCH (selected:Table)-[:REFERENCES*1..2]-(related:Table)
                WHERE selected.name IN $selected_tables 
                  AND NOT related.name IN $selected_tables
                RETURN DISTINCT related.name as related_table, 
                       related.comment as comment,
                       shortestPath((selected)-[:REFERENCES*1..2]-(related)) as path
                ORDER BY length(path), related_table
                LIMIT 3
                """
                
                expand_results = session.run(expand_query, selected_tables=selected_tables)
                
                for record in expand_results:
                    related_table = record['related_table']
                    comment = record['comment']
                    path_length = len(record['path'].relationships)
                    
                    # ê´€ê³„ ê±°ë¦¬ê°€ ê°€ê¹Œìš´ ì¤‘ìš”í•œ í…Œì´ë¸”ë§Œ ì¶”ê°€
                    if path_length <= 2:
                        selected_tables.append(related_table)
                        print(f"  + {related_table}: {comment} (ê±°ë¦¬: {path_length})")
            
            # 3ë‹¨ê³„: í´ë°± - LLM ë¶„ì„ì´ ì‹¤íŒ¨í•œ ê²½ìš°
            if not selected_tables:
                print("âš ï¸ LLM ë¶„ì„ ì‹¤íŒ¨. ê·¸ë˜í”„ ì¤‘ì‹¬ì„± ê¸°ë°˜ìœ¼ë¡œ ì£¼ìš” í…Œì´ë¸” ì„ íƒ...")
                
                # í…Œì´ë¸” ì¤‘ì‹¬ì„±(ì—°ê²°ë„) ê¸°ë°˜ ì„ íƒ
                centrality_query = """
                MATCH (t:Table)
                OPTIONAL MATCH (t)-[r:REFERENCES]-(other:Table)
                WITH t, count(r) as connections
                ORDER BY connections DESC, t.name
                LIMIT 4
                RETURN t.name as table_name, t.comment as comment, connections
                """
                
                centrality_results = session.run(centrality_query)
                for record in centrality_results:
                    table_name = record['table_name']
                    comment = record['comment']
                    connections = record['connections']
                    selected_tables.append(table_name)
                    print(f"  - {table_name}: {comment} (ì—°ê²°ìˆ˜: {connections})")
            
            # 4ë‹¨ê³„: ìµœì¢… ê²€ì¦ ë° ì •ë¦¬
            final_tables = []
            for table in selected_tables:
                if table in self.table_schemas and table not in final_tables:
                    final_tables.append(table)
            
            print(f"âœ… ìµœì¢… ì„ íƒëœ í…Œì´ë¸”: {final_tables}")
            return final_tables[:6]  # ìµœëŒ€ 6ê°œ í…Œì´ë¸”ë¡œ ì œí•œ
    
    def analyze_table_role_from_columns(self, table_name: str) -> Dict[str, Any]:
        """ì»¬ëŸ¼ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ í…Œì´ë¸”ì˜ ì—­í• ê³¼ ì˜ë¯¸ ì¶”ì •"""
        if not self.neo4j_driver or table_name not in self.table_schemas:
            return {}
        
        schema = self.table_schemas[table_name]
        columns = schema.columns
        
        analysis = {
            'table_name': table_name,
            'estimated_role': '',
            'table_type': '',
            'business_purpose': '',
            'column_patterns': [],
            'confidence_score': 0.0
        }
        
        # ì»¬ëŸ¼ëª… íŒ¨í„´ ë¶„ì„
        column_names = [col['name'].lower() for col in columns]
        column_types = [col['type'].upper() for col in columns]
        
        print(f"ğŸ” '{table_name}' í…Œì´ë¸” ì»¬ëŸ¼ ë¶„ì„ ì¤‘...")
        print(f"ğŸ“‹ ì»¬ëŸ¼ë“¤: {column_names}")
        
        # 1. ê¸°ë³¸ í…Œì´ë¸” íƒ€ì… ë¶„ë¥˜
        confidence_scores = {}
        
        # ë§ˆìŠ¤í„° ë°ì´í„° í…Œì´ë¸” íŒ¨í„´
        master_patterns = [
            (['name', 'title', 'description'], 'ë§ˆìŠ¤í„° ë°ì´í„°'),
            (['category', 'type', 'status'], 'ë¶„ë¥˜/ì¹´í…Œê³ ë¦¬'),
            (['code', 'value', 'display'], 'ì½”ë“œ í…Œì´ë¸”'),
            (['config', 'setting', 'param'], 'ì„¤ì • í…Œì´ë¸”')
        ]
        
        # íŠ¸ëœì­ì…˜ í…Œì´ë¸” íŒ¨í„´
        transaction_patterns = [
            (['order', 'purchase', 'payment'], 'ì£¼ë¬¸/ê±°ë˜'),
            (['amount', 'price', 'total', 'quantity'], 'ê±°ë˜ ìƒì„¸'),
            (['date', 'time', 'created_at', 'updated_at'], 'ì‹œê³„ì—´ ë°ì´í„°'),
            (['from', 'to', 'source', 'target'], 'ì´ë™/ì „ì†¡ ë°ì´í„°')
        ]
        
        # ê´€ê³„ í…Œì´ë¸” íŒ¨í„´
        relation_patterns = [
            (['_id', 'id'], 'ì—°ê²° í…Œì´ë¸”'),
            (['mapping', 'link', 'ref'], 'ë§¤í•‘ í…Œì´ë¸”'),
            (['item', 'detail', 'line'], 'ìƒì„¸ í…Œì´ë¸”')
        ]
        
        # ë¡œê·¸/ì´ë²¤íŠ¸ í…Œì´ë¸” íŒ¨í„´
        log_patterns = [
            (['log', 'event', 'history'], 'ë¡œê·¸/ì´ë²¤íŠ¸'),
            (['audit', 'trace', 'track'], 'ê°ì‚¬/ì¶”ì '),
            (['session', 'visit', 'click'], 'ì‚¬ìš©ì í–‰ë™')
        ]
        
        # íŒ¨í„´ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚°
        def calculate_pattern_score(patterns, category_name):
            max_score = 0
            matched_pattern = []
            
            for pattern_keywords, description in patterns:
                score = 0
                matches = []
                
                for keyword in pattern_keywords:
                    for col_name in column_names:
                        if keyword in col_name:
                            score += 1
                            matches.append(f"{col_name}({keyword})")
                
                if score > max_score:
                    max_score = score
                    matched_pattern = [description, matches]
            
            if max_score > 0:
                confidence_scores[category_name] = (max_score / len(column_names), matched_pattern)
            
            return max_score
        
        # ê° íŒ¨í„´ë³„ ì ìˆ˜ ê³„ì‚°
        master_score = calculate_pattern_score(master_patterns, 'master')
        transaction_score = calculate_pattern_score(transaction_patterns, 'transaction')
        relation_score = calculate_pattern_score(relation_patterns, 'relation')
        log_score = calculate_pattern_score(log_patterns, 'log')
        
        # 2. íŠ¹ìˆ˜ ì»¬ëŸ¼ íŒ¨í„´ ë¶„ì„
        special_patterns = []
        
        # ID ì»¬ëŸ¼ ë¶„ì„
        id_columns = [col for col in column_names if 'id' in col]
        if len(id_columns) > 2:
            special_patterns.append(f"ë‹¤ì¤‘ ID ì»¬ëŸ¼ ({len(id_columns)}ê°œ) - ê´€ê³„í˜• í…Œì´ë¸”")
        
        # ì‹œê°„ ì»¬ëŸ¼ ë¶„ì„
        time_columns = [col for col in column_names if any(keyword in col for keyword in ['date', 'time', 'created', 'updated', 'modified'])]
        if time_columns:
            special_patterns.append(f"ì‹œê°„ ì¶”ì  ì»¬ëŸ¼ - ì´ë²¤íŠ¸/ë¡œê·¸ì„± í…Œì´ë¸”")
        
        # ê¸ˆì•¡/ìˆ˜ëŸ‰ ì»¬ëŸ¼ ë¶„ì„
        money_columns = [col for col in column_names if any(keyword in col for keyword in ['amount', 'price', 'cost', 'total', 'quantity', 'count'])]
        if money_columns:
            special_patterns.append(f"ê¸ˆì•¡/ìˆ˜ëŸ‰ ì»¬ëŸ¼ - ê±°ë˜/ì£¼ë¬¸ í…Œì´ë¸”")
        
        # ìƒíƒœ ì»¬ëŸ¼ ë¶„ì„
        status_columns = [col for col in column_names if any(keyword in col for keyword in ['status', 'state', 'flag', 'active'])]
        if status_columns:
            special_patterns.append(f"ìƒíƒœ ê´€ë¦¬ ì»¬ëŸ¼ - ì›Œí¬í”Œë¡œìš° í…Œì´ë¸”")
        
        # 3. ìµœì¢… ì—­í•  ì¶”ì •
        if confidence_scores:
            # ê°€ì¥ ë†’ì€ ì ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
            best_category = max(confidence_scores.items(), key=lambda x: x[1][0])
            category_name = best_category[0]
            score, (description, matches) = best_category[1]
            
            analysis['table_type'] = category_name
            analysis['estimated_role'] = description
            analysis['confidence_score'] = score
            analysis['column_patterns'] = special_patterns
            
            # ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì  ì¶”ì •
            if category_name == 'master':
                analysis['business_purpose'] = f"ê¸°ì¤€ ì •ë³´ ê´€ë¦¬ - {table_name}ì˜ ë§ˆìŠ¤í„° ë°ì´í„° ì €ì¥"
            elif category_name == 'transaction':
                analysis['business_purpose'] = f"ê±°ë˜ ë°ì´í„° ì²˜ë¦¬ - {table_name} ê´€ë ¨ íŠ¸ëœì­ì…˜ ê¸°ë¡"
            elif category_name == 'relation':
                analysis['business_purpose'] = f"ë°ì´í„° ì—°ê²° - ë‹¤ë¥¸ í…Œì´ë¸”ë“¤ ê°„ì˜ ê´€ê³„ ì •ì˜"
            elif category_name == 'log':
                analysis['business_purpose'] = f"ì´ë²¤íŠ¸ ì¶”ì  - {table_name} ê´€ë ¨ í™œë™ ë¡œê·¸"
            
            print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼:")
            print(f"  - í…Œì´ë¸” íƒ€ì…: {category_name}")
            print(f"  - ì¶”ì • ì—­í• : {description}")
            print(f"  - ì‹ ë¢°ë„: {score:.2f}")
            print(f"  - ë§¤ì¹­ íŒ¨í„´: {matches}")
            print(f"  - íŠ¹ìˆ˜ íŒ¨í„´: {special_patterns}")
            print(f"  - ë¹„ì¦ˆë‹ˆìŠ¤ ëª©ì : {analysis['business_purpose']}")
        else:
            analysis['estimated_role'] = "ì¼ë°˜ ë°ì´í„° í…Œì´ë¸”"
            analysis['table_type'] = "general"
            analysis['business_purpose'] = f"{table_name} ê´€ë ¨ ì •ë³´ ì €ì¥"
            analysis['column_patterns'] = special_patterns
            
            print(f"ğŸ“Š ë¶„ì„ ê²°ê³¼: íŠ¹ë³„í•œ íŒ¨í„´ì´ ë°œê²¬ë˜ì§€ ì•ŠìŒ - ì¼ë°˜ í…Œì´ë¸”")
        
        return analysis
    
    def enrich_table_metadata_with_column_analysis(self):
        """ëª¨ë“  í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ë¶„ì„ ê²°ê³¼ë¥¼ Neo4jì— ì¶”ê°€"""
        if not self.neo4j_driver:
            print("âŒ Neo4j ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        print("ğŸ”„ ì»¬ëŸ¼ ë¶„ì„ ê¸°ë°˜ í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê°•í™” ì¤‘...")
        
        with self.neo4j_driver.session() as session:
            for table_name in self.table_schemas.keys():
                # ì»¬ëŸ¼ ë¶„ì„ ìˆ˜í–‰
                analysis = self.analyze_table_role_from_columns(table_name)
                
                if analysis:
                    # Neo4jì— ë¶„ì„ ê²°ê³¼ ì—…ë°ì´íŠ¸
                    update_query = """
                    MATCH (t:Table {name: $table_name})
                    SET t.estimated_role = $estimated_role,
                        t.table_type = $table_type,
                        t.business_purpose = $business_purpose,
                        t.confidence_score = $confidence_score,
                        t.column_patterns = $column_patterns
                    RETURN t
                    """
                    
                    session.run(update_query,
                        table_name=table_name,
                        estimated_role=analysis['estimated_role'],
                        table_type=analysis['table_type'],
                        business_purpose=analysis['business_purpose'],
                        confidence_score=analysis['confidence_score'],
                        column_patterns=analysis['column_patterns']
                    )
                    
                    print(f"âœ… {table_name} ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
        
        print("ğŸ‰ ëª¨ë“  í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê°•í™” ì™„ë£Œ!")
    
    def analyze_table_role_from_data_values(self, table_name: str) -> Dict[str, Any]:
        """ì‹¤ì œ ì»¬ëŸ¼ ê°’(ë°ì´í„°)ì„ ë¶„ì„í•˜ì—¬ í…Œì´ë¸”ì˜ ì—­í• ê³¼ ì„±ê²© ì¶”ì •"""
        if not self.connection or table_name not in self.table_schemas:
            return {}
        
        print(f"ğŸ” '{table_name}' í…Œì´ë¸”ì˜ ì‹¤ì œ ë°ì´í„° ê°’ ë¶„ì„ ì¤‘...")
        
        analysis = {
            'table_name': table_name,
            'data_patterns': [],
            'estimated_role': '',
            'data_characteristics': {},
            'confidence_score': 0.0,
            'sample_insights': []
        }
        
        try:
            with self.connection.cursor() as cursor:
                # 1. ê¸°ë³¸ í†µê³„ ì •ë³´ ìˆ˜ì§‘
                cursor.execute(f"SELECT COUNT(*) as total_rows FROM {table_name}")
                total_rows = cursor.fetchone()[0]
                
                if total_rows == 0:
                    analysis['estimated_role'] = "ë¹ˆ í…Œì´ë¸” - ë°ì´í„° ì—†ìŒ"
                    return analysis
                
                analysis['data_characteristics']['total_rows'] = total_rows
                print(f"ğŸ“Š ì´ ë ˆì½”ë“œ ìˆ˜: {total_rows}")
                
                # 2. ìƒ˜í”Œ ë°ì´í„°ë¡œ íŒ¨í„´ ë¶„ì„
                schema = self.table_schemas[table_name]
                sample_size = min(100, total_rows)  # ìµœëŒ€ 100ê°œ ìƒ˜í”Œ
                
                cursor.execute(f"SELECT * FROM {table_name} LIMIT {sample_size}")
                sample_data = cursor.fetchall()
                
                if not sample_data:
                    return analysis
                
                # ì»¬ëŸ¼ë³„ ë°ì´í„° íŒ¨í„´ ë¶„ì„
                columns = schema.columns
                insights = []
                
                for i, column in enumerate(columns):
                    col_name = column['name']
                    col_values = [row[i] for row in sample_data if row[i] is not None]
                    
                    if not col_values:
                        continue
                    
                    col_analysis = self._analyze_column_values(col_name, col_values, total_rows)
                    if col_analysis:
                        insights.append(col_analysis)
                
                analysis['sample_insights'] = insights
                
                # 3. í…Œì´ë¸” ì—­í•  ì¶”ì •
                role_estimation = self._estimate_table_role_from_data_patterns(insights, total_rows)
                analysis.update(role_estimation)
                
                print(f"ğŸ“ˆ ë°ì´í„° ê¸°ë°˜ ë¶„ì„ ê²°ê³¼:")
                print(f"  - ì¶”ì • ì—­í• : {analysis['estimated_role']}")
                print(f"  - ì‹ ë¢°ë„: {analysis['confidence_score']:.2f}")
                for insight in insights[:3]:  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                    print(f"  - {insight}")
                
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            analysis['estimated_role'] = "ë¶„ì„ ì‹¤íŒ¨"
        
        return analysis
    
    def _analyze_column_values(self, col_name: str, values: list, total_rows: int) -> str:
        """ê°œë³„ ì»¬ëŸ¼ì˜ ê°’ë“¤ì„ ë¶„ì„í•˜ì—¬ íŒ¨í„´ íŒŒì•…"""
        if not values:
            return ""
        
        unique_count = len(set(values))
        sample_count = len(values)
        
        # ìœ ë‹ˆí¬ ë¹„ìœ¨ ê³„ì‚°
        uniqueness_ratio = unique_count / sample_count
        
        # ê°’ íƒ€ì… ë¶„ì„
        value_types = set(type(v).__name__ for v in values)
        
        insights = []
        
        # 1. ID íŒ¨í„´ ë¶„ì„
        if 'id' in col_name.lower():
            if uniqueness_ratio > 0.95:
                insights.append(f"{col_name}: ê³ ìœ  ì‹ë³„ì (ìœ ë‹ˆí¬ìœ¨ {uniqueness_ratio:.2f})")
            elif uniqueness_ratio < 0.3:
                insights.append(f"{col_name}: ì™¸ë˜í‚¤/ì°¸ì¡°í‚¤ (ì¤‘ë³µìœ¨ ë†’ìŒ)")
        
        # 2. ì´ë¦„/í…ìŠ¤íŠ¸ íŒ¨í„´ ë¶„ì„
        if any(keyword in col_name.lower() for keyword in ['name', 'title', 'description']):
            if 'str' in value_types:
                avg_length = sum(len(str(v)) for v in values) / len(values)
                if avg_length > 50:
                    insights.append(f"{col_name}: ìƒì„¸ ì„¤ëª… í…ìŠ¤íŠ¸ (í‰ê·  {avg_length:.0f}ì)")
                else:
                    insights.append(f"{col_name}: ì§§ì€ ì´ë¦„/ì œëª© (í‰ê·  {avg_length:.0f}ì)")
        
        # 3. ìˆ«ì íŒ¨í„´ ë¶„ì„
        if any(t in value_types for t in ['int', 'float', 'Decimal']):
            numeric_values = [float(v) for v in values if isinstance(v, (int, float)) or (hasattr(v, '__float__'))]
            if numeric_values:
                min_val, max_val = min(numeric_values), max(numeric_values)
                avg_val = sum(numeric_values) / len(numeric_values)
                
                if 'price' in col_name.lower() or 'amount' in col_name.lower():
                    insights.append(f"{col_name}: ê¸ˆì•¡ ë°ì´í„° (í‰ê·  {avg_val:,.0f}, ë²”ìœ„ {min_val:,.0f}~{max_val:,.0f})")
                elif 'quantity' in col_name.lower() or 'count' in col_name.lower():
                    insights.append(f"{col_name}: ìˆ˜ëŸ‰ ë°ì´í„° (í‰ê·  {avg_val:.1f}, ë²”ìœ„ {min_val}~{max_val})")
                elif max_val <= 5 and min_val >= 1:
                    insights.append(f"{col_name}: í‰ì /ë“±ê¸‰ ë°ì´í„° (1~5 ë²”ìœ„)")
        
        # 4. ìƒíƒœ/ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ë¶„ì„
        if uniqueness_ratio < 0.2 and 'str' in value_types:
            common_values = list(set(values))[:5]
            insights.append(f"{col_name}: ì¹´í…Œê³ ë¦¬/ìƒíƒœ ë°ì´í„° (ê°’: {common_values})")
        
        # 5. ë‚ ì§œ/ì‹œê°„ íŒ¨í„´ ë¶„ì„
        if any(keyword in col_name.lower() for keyword in ['date', 'time', 'created', 'updated']):
            insights.append(f"{col_name}: ì‹œê°„ ì¶”ì  ë°ì´í„° (ì‹œê³„ì—´)")
        
        return " | ".join(insights) if insights else ""
    
    def _estimate_table_role_from_data_patterns(self, insights: list, total_rows: int) -> Dict[str, Any]:
        """ë°ì´í„° íŒ¨í„´ì„ ì¢…í•©í•˜ì—¬ í…Œì´ë¸” ì—­í•  ì¶”ì •"""
        insight_text = " ".join(insights).lower()
        
        role_scores = {
            'master_data': 0,
            'transaction': 0,
            'lookup_table': 0,
            'log_table': 0,
            'relation_table': 0
        }
        
        # ë§ˆìŠ¤í„° ë°ì´í„° íŒ¨í„´
        if any(keyword in insight_text for keyword in ['ê³ ìœ  ì‹ë³„ì', 'ì´ë¦„', 'ì„¤ëª…', 'ìƒì„¸']):
            role_scores['master_data'] += 2
        
        # íŠ¸ëœì­ì…˜ íŒ¨í„´
        if any(keyword in insight_text for keyword in ['ê¸ˆì•¡', 'ìˆ˜ëŸ‰', 'ì‹œê°„ ì¶”ì ']):
            role_scores['transaction'] += 3
        
        # ë£©ì—…/ì½”ë“œ í…Œì´ë¸” íŒ¨í„´
        if 'ì¹´í…Œê³ ë¦¬/ìƒíƒœ' in insight_text and total_rows < 100:
            role_scores['lookup_table'] += 3
        
        # ë¡œê·¸ í…Œì´ë¸” íŒ¨í„´
        if total_rows > 1000 and 'ì‹œê°„ ì¶”ì ' in insight_text:
            role_scores['log_table'] += 2
        
        # ê´€ê³„ í…Œì´ë¸” íŒ¨í„´
        if insight_text.count('ì™¸ë˜í‚¤') >= 2:
            role_scores['relation_table'] += 3
        
        # ìµœê³  ì ìˆ˜ ì—­í•  ì„ íƒ
        if max(role_scores.values()) > 0:
            best_role = max(role_scores.items(), key=lambda x: x[1])
            role_name, score = best_role
            
            role_mapping = {
                'master_data': 'ë§ˆìŠ¤í„° ë°ì´í„° í…Œì´ë¸” - ê¸°ì¤€ ì •ë³´ ì €ì¥',
                'transaction': 'íŠ¸ëœì­ì…˜ í…Œì´ë¸” - ì—…ë¬´ ê±°ë˜ ë°ì´í„°',
                'lookup_table': 'ë£©ì—… í…Œì´ë¸” - ì½”ë“œ/ì¹´í…Œê³ ë¦¬ ê´€ë¦¬',
                'log_table': 'ë¡œê·¸ í…Œì´ë¸” - ì´ë²¤íŠ¸/í™œë™ ê¸°ë¡',
                'relation_table': 'ê´€ê³„ í…Œì´ë¸” - í…Œì´ë¸” ê°„ ì—°ê²°'
            }
            
            return {
                'estimated_role': role_mapping[role_name],
                'confidence_score': min(score / 5.0, 1.0),  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”
                'data_patterns': [role_name]
            }
        else:
            return {
                'estimated_role': 'ì¼ë°˜ ë°ì´í„° í…Œì´ë¸”',
                'confidence_score': 0.1,
                'data_patterns': ['general']
            }
    
    def enrich_metadata_with_data_analysis(self):
        """í…Œì´ë¸” ì„¤ëª…ì´ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ ì‹¤ì œ ë°ì´í„° ê°’ ë¶„ì„ ê²°ê³¼ë¥¼ Neo4jì— ì¶”ê°€"""
        if not self.neo4j_driver or not self.connection:
            print("âŒ Neo4jì™€ MariaDB ì—°ê²°ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")
            return
        
        print("ğŸ”„ ì„¤ëª… ë¶€ì¡± í…Œì´ë¸”ì˜ ì‹¤ì œ ë°ì´í„° ê°’ ë¶„ì„ìœ¼ë¡œ ë©”íƒ€ë°ì´í„° ê°•í™” ì¤‘...")
        
        with self.neo4j_driver.session() as session:
            for table_name in self.table_schemas.keys():
                schema = self.table_schemas[table_name]
                table_comment = schema.comment
                
                # í…Œì´ë¸” ì„¤ëª…ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš°ì—ë§Œ ë°ì´í„° ê°’ ë¶„ì„ ìˆ˜í–‰
                should_analyze = (
                    not table_comment or 
                    len(table_comment.strip()) < 10 or
                    table_comment.strip() == table_name or
                    "í…Œì´ë¸”" in table_comment and len(table_comment) < 20
                )
                
                if should_analyze:
                    print(f"\nğŸ“Š {table_name} í…Œì´ë¸” - ì„¤ëª… ë¶€ì¡±ìœ¼ë¡œ ë°ì´í„° ê°’ ë¶„ì„ ìˆ˜í–‰...")
                    print(f"   í˜„ì¬ ì„¤ëª…: '{table_comment}'")
                    
                    # ë°ì´í„° ê°’ ë¶„ì„ ìˆ˜í–‰
                    data_analysis = self.analyze_table_role_from_data_values(table_name)
                    
                    if data_analysis and data_analysis.get('estimated_role'):
                        # Neo4jì— ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì¶”ê°€
                        update_query = """
                        MATCH (t:Table {name: $table_name})
                        SET t.data_estimated_role = $data_estimated_role,
                            t.data_confidence_score = $data_confidence_score,
                            t.data_patterns = $data_patterns,
                            t.total_rows = $total_rows,
                            t.enhanced_comment = coalesce(t.comment, '') + ' [ë°ì´í„°ë¶„ì„: ' + $data_estimated_role + ']'
                        RETURN t
                        """
                        
                        session.run(update_query,
                            table_name=table_name,
                            data_estimated_role=data_analysis['estimated_role'],
                            data_confidence_score=data_analysis['confidence_score'],
                            data_patterns=data_analysis['data_patterns'],
                            total_rows=data_analysis['data_characteristics'].get('total_rows', 0)
                        )
                        
                        print(f"âœ… {table_name} ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
                else:
                    print(f"â­ï¸  {table_name} í…Œì´ë¸” - ì¶©ë¶„í•œ ì„¤ëª… ì¡´ì¬, ë°ì´í„° ë¶„ì„ ìŠ¤í‚µ")
                    print(f"   í˜„ì¬ ì„¤ëª…: '{table_comment}'")
        
        print("ğŸ‰ ì„¤ëª… ë¶€ì¡± í…Œì´ë¸”ë“¤ì˜ ì‹¤ì œ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
    
    def find_optimal_join_sequence(self, required_tables: List[str]) -> List[Dict]:
        """í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ì¡°ì¸í•˜ëŠ” ìµœì  ìˆœì„œ ì°¾ê¸°"""
        if not self.neo4j_driver or len(required_tables) < 2:
            return []
        
        print(f"ğŸ” í…Œì´ë¸” ì¡°ì¸ ìˆœì„œ ë¶„ì„: {required_tables}")
        
        with self.neo4j_driver.session() as session:
            # ëª¨ë“  í…Œì´ë¸” ìŒì— ëŒ€í•œ ìµœë‹¨ ê²½ë¡œ ì°¾ê¸°
            join_sequences = []
            
            query = """
            MATCH (t1:Table), (t2:Table)
            WHERE t1.name IN $tables AND t2.name IN $tables AND t1 <> t2
            MATCH path = shortestPath((t1)-[:REFERENCES*1..3]-(t2))
            RETURN t1.name as table1, t2.name as table2, path, length(path) as distance
            ORDER BY distance
            """
            
            result = session.run(query, tables=required_tables)
            
            connections = {}
            for record in result:
                table1 = record['table1']
                table2 = record['table2']
                distance = record['distance']
                path = record['path']
                
                # ê²½ë¡œì—ì„œ ê´€ê³„ ì •ë³´ ì¶”ì¶œ
                relationships = []
                for i in range(len(path.relationships)):
                    rel = path.relationships[i]
                    relationships.append({
                        'from_table': path.nodes[i]['name'],
                        'to_table': path.nodes[i+1]['name'],
                        'from_column': rel['from_column'],
                        'to_column': rel['to_column'],
                        'confidence': rel['confidence']
                    })
                
                key = tuple(sorted([table1, table2]))
                if key not in connections or distance < connections[key]['distance']:
                    connections[key] = {
                        'distance': distance,
                        'relationships': relationships
                    }
            
            # ìµœì  ì¡°ì¸ ìˆœì„œ ìƒì„±
            if connections:
                # ê°€ì¥ ì—°ê²°ì´ ë°€ì§‘ëœ í…Œì´ë¸”ë¶€í„° ì‹œì‘
                start_table = max(required_tables, key=lambda t: 
                    sum(1 for k in connections.keys() if t in k))
                
                remaining_tables = set(required_tables) - {start_table}
                join_sequence = [{'table': start_table, 'joins': []}]
                
                while remaining_tables:
                    # í˜„ì¬ ì—°ê²°ëœ í…Œì´ë¸”ë“¤ê³¼ ê°€ì¥ ê°€ê¹Œìš´ ë‹¤ìŒ í…Œì´ë¸” ì°¾ê¸°
                    connected_tables = {start_table} | {j['to_table'] for seq in join_sequence for j in seq['joins']}
                    
                    best_next = None
                    best_distance = float('inf')
                    best_join_info = None
                    
                    for remaining in remaining_tables:
                        for connected in connected_tables:
                            key = tuple(sorted([connected, remaining]))
                            if key in connections and connections[key]['distance'] < best_distance:
                                best_distance = connections[key]['distance']
                                best_next = remaining
                                best_join_info = connections[key]['relationships']
                    
                    if best_next:
                        join_sequence.append({
                            'table': best_next,
                            'joins': best_join_info
                        })
                        remaining_tables.remove(best_next)
                    else:
                        # ì—°ê²°í•  ìˆ˜ ì—†ëŠ” í…Œì´ë¸”ë“¤ (ê°•ì œë¡œ ì¶”ê°€)
                        for remaining in remaining_tables:
                            join_sequence.append({
                                'table': remaining,
                                'joins': []
                            })
                        break
                
                return join_sequence
            
            return []
    
    def generate_schema_prompt(self) -> str:
        """í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ë³€í™˜"""
        prompt = "ë‹¤ìŒì€ ë°ì´í„°ë² ì´ìŠ¤ì˜ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´ì…ë‹ˆë‹¤:\n\n"
        
        for table_name, info in self.tables_info.items():
            prompt += f"í…Œì´ë¸”: {table_name}\n"
            prompt += "ì»¬ëŸ¼:\n"
            
            for col in info['columns']:
                col_name, col_type = col[0], col[1]
                prompt += f"  - {col_name}: {col_type}\n"
            
            if info['sample_data']:
                prompt += "ìƒ˜í”Œ ë°ì´í„°:\n"
                for i, row in enumerate(info['sample_data'][:2], 1):
                    prompt += f"  {i}: {row}\n"
            
            prompt += "\n"
        
        return prompt
    
    def generate_hybrid_sql_query(self, user_request: str) -> Optional[str]:
        """Neo4j ê·¸ë˜í”„ ì •ë³´ë¥¼ í™œìš©í•œ í•˜ì´ë¸Œë¦¬ë“œ SQL ì¿¼ë¦¬ ìƒì„±"""
        # 1. ì‚¬ìš©ì ìš”ì²­ì—ì„œ ê´€ë ¨ í…Œì´ë¸” ì¶”ì¶œ
        relevant_tables = self.extract_relevant_tables(user_request)
        
        if not relevant_tables:
            print("âŒ ê´€ë ¨ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ“Š ê´€ë ¨ í…Œì´ë¸”: {relevant_tables}")
        
        # 2. Neo4jì—ì„œ ìµœì  ì¡°ì¸ ìˆœì„œ ì°¾ê¸°
        join_sequence = self.find_optimal_join_sequence(relevant_tables)
        
        # 3. ê·¸ë˜í”„ ì •ë³´ì™€ ìŠ¤í‚¤ë§ˆë¥¼ í™œìš©í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        enhanced_prompt = self.generate_enhanced_prompt(user_request, relevant_tables, join_sequence)
        
        # 4. LLMìœ¼ë¡œ ì¿¼ë¦¬ ìƒì„±
        print("ğŸ¤– Neo4j ê·¸ë˜í”„ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ SQL ì¿¼ë¦¬ ìƒì„± ì¤‘...")
        response = self.call_llm(enhanced_prompt)
        
        if response:
            # SQL ì¿¼ë¦¬ ì¶”ì¶œ
            lines = response.split('\n')
            sql_lines = []
            in_sql = False
            
            for line in lines:
                line = line.strip()
                if line.upper().startswith('SELECT'):
                    in_sql = True
                if in_sql:
                    sql_lines.append(line)
                    if line.endswith(';'):
                        break
            
            if sql_lines:
                sql_query = ' '.join(sql_lines)
                if not sql_query.endswith(';'):
                    sql_query += ';'
                return sql_query
        
        return None
    
    def extract_relevant_tables_with_llm(self, user_request: str) -> List[str]:
        """LLMì„ í™œìš©í•œ ì§€ëŠ¥ì  í…Œì´ë¸” ì¶”ì¶œ"""
        # ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ ê°„ê²°í•˜ê²Œ ì •ë¦¬
        table_descriptions = {}
        for table_name, schema in self.table_schemas.items():
            table_descriptions[table_name] = {
                'description': schema.comment,
                'key_columns': [col['name'] for col in schema.columns]  # ì£¼ìš” ì»¬ëŸ¼ 4ê°œë§Œ
            }
        
        # LLMìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
        schema_summary = "ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì •ë³´:\n"
        for table, info in table_descriptions.items():
            schema_summary += f"- {table}: {info['description']}\n"
            schema_summary += f"  ì£¼ìš” ì»¬ëŸ¼: {', '.join(info['key_columns'])}\n"
        
        # LLM íƒ€ì…ê³¼ ëª¨ë¸ë³„ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
        if self.llm_type == "claude":
            # ClaudeëŠ” í•œê¸€ì„ ë§¤ìš° ì˜ ì§€ì›í•˜ë¯€ë¡œ ìƒì„¸í•œ í•œê¸€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = f"""{schema_summary}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ”ë° í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

ë¶„ì„ ê¸°ì¤€:
1. ì‚¬ìš©ìê°€ ì¡°íšŒí•˜ë ¤ëŠ” ì£¼ìš” ë°ì´í„°ëŠ” ë¬´ì—‡ì¸ê°€?
2. ê·¸ ë°ì´í„°ë¥¼ ì–»ê¸° ìœ„í•´ ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ í•„ìš”í•œê°€?
3. í…Œì´ë¸” ê°„ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ê²°ì— í•„ìš”í•œ ì¤‘ê°„ í…Œì´ë¸”ë„ í¬í•¨í•´ì•¼ í•˜ëŠ”ê°€?

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
{{"tables": ["table1", "table2", "table3"], "reason": "ì„ íƒ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ"}}"""
        elif "gemma" in self.model_name.lower():
            # Gemma ëª¨ë¸ìš© íŠ¹ë³„ í”„ë¡¬í”„íŠ¸
            prompt = f"""{schema_summary}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ”ë° í•„ìš”í•œ í…Œì´ë¸”ë“¤ì„ ì„ íƒí•´ì£¼ì„¸ìš”.

**ë¶„ì„ ê¸°ì¤€**:
1. ì‚¬ìš©ìê°€ ì¡°íšŒí•˜ë ¤ëŠ” ì£¼ìš” ë°ì´í„°ëŠ” ë¬´ì—‡ì¸ê°€?
2. ê·¸ ë°ì´í„°ë¥¼ ì–»ê¸° ìœ„í•´ ì–´ë–¤ í…Œì´ë¸”ë“¤ì´ í•„ìš”í•œê°€?
3. í…Œì´ë¸” ê°„ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ì—°ê²°ì— í•„ìš”í•œ ì¤‘ê°„ í…Œì´ë¸”ë„ í¬í•¨í•´ì•¼ í•˜ëŠ”ê°€?

**ì‘ë‹µ í˜•ì‹** (JSONë§Œ ë°˜í™˜):
{{"tables": ["table1", "table2", "table3"], "reason": "ì„ íƒ ì´ìœ ë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ"}}

JSON:"""
        else:
            # ê¸°ë³¸ ëª¨ë¸ìš© í”„ë¡¬í”„íŠ¸
            prompt = f"""{schema_summary}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” ì •í™•í•œ SELECT SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
{{"tables": ["í…Œì´ë¸”ëª…1", "í…Œì´ë¸”ëª…2"], "reason": "ì„ íƒ ì´ìœ "}}

JSON:"""
        
        print("ğŸ§  LLMì´ ê´€ë ¨ í…Œì´ë¸”ì„ ë¶„ì„ ì¤‘...")
        response = self.call_llm(prompt)
        
        if response:
            try:
                # JSON ì¶”ì¶œ
                response = response.strip()
                
                # JSON ë¸”ë¡ ì°¾ê¸°
                json_start = response.find('{')
                json_end = response.rfind('}') + 1
                
                if json_start >= 0 and json_end > json_start:
                    json_str = response[json_start:json_end]
                    result = json.loads(json_str)
                    
                    if 'tables' in result and isinstance(result['tables'], list):
                        # ìœ íš¨í•œ í…Œì´ë¸”ë§Œ í•„í„°ë§
                        valid_tables = [
                            table for table in result['tables'] 
                            if table in self.table_schemas
                        ]
                        
                        if valid_tables:
                            print(f"ğŸ¯ LLM ë¶„ì„ ê²°ê³¼: {valid_tables}")
                            if 'reason' in result:
                                print(f"ğŸ“ ì„ íƒ ì´ìœ : {result['reason']}")
                            return valid_tables
                        
            except (json.JSONDecodeError, KeyError) as e:
                print(f"âš ï¸  LLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
                print(f"ğŸ“„ ì›ë³¸ ì‘ë‹µ: {response[:200]}...")
        
        # LLM ë¶„ì„ ì‹¤íŒ¨ì‹œ í‚¤ì›Œë“œ ê¸°ë°˜ ë°©ì‹ìœ¼ë¡œ í´ë°±
        print("ğŸ”„ í‚¤ì›Œë“œ ê¸°ë°˜ ë°©ì‹ìœ¼ë¡œ í´ë°±...")
        return self.extract_relevant_tables_fallback(user_request)
    
    def extract_relevant_tables_fallback(self, user_request: str) -> List[str]:
        """í‚¤ì›Œë“œ ê¸°ë°˜ í´ë°± ë°©ì‹"""
        request_lower = user_request.lower()
        relevant_tables = []
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í…Œì´ë¸” ë§¤ì¹­
        table_keywords = {
            'users': ['ì‚¬ìš©ì', 'ìœ ì €', 'ê³ ê°', 'íšŒì›', 'ì‚¬ëŒ'],
            'products': ['ìƒí’ˆ', 'ì œí’ˆ', 'ì•„ì´í…œ', 'ë¬¼ê±´'],
            'orders': ['ì£¼ë¬¸', 'êµ¬ë§¤', 'ê²°ì œ'],
            'order_items': ['ì£¼ë¬¸ìƒì„¸', 'ì£¼ë¬¸ë‚´ì—­', 'êµ¬ë§¤ë‚´ì—­'],
            'categories': ['ì¹´í…Œê³ ë¦¬', 'ë¶„ë¥˜', 'ì¢…ë¥˜'],
            'reviews': ['ë¦¬ë·°', 'í‰ì ', 'í‰ê°€', 'í›„ê¸°']
        }
        
        for table, keywords in table_keywords.items():
            if any(keyword in request_lower for keyword in keywords):
                relevant_tables.append(table)
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ê´€ë ¨ì„±ì´ ë†’ì€ í…Œì´ë¸”ë“¤ ì¶”ê°€
        if not relevant_tables:
            relevant_tables = ['users', 'products', 'orders']
        
        return relevant_tables
    
    def extract_relevant_tables(self, user_request: str) -> List[str]:
        """ì‚¬ìš©ì ìš”ì²­ì—ì„œ ê´€ë ¨ í…Œì´ë¸” ì¶”ì¶œ (ê·¸ë˜í”„ ê¸°ë°˜ ê²€ìƒ‰)"""
        # Neo4j ê·¸ë˜í”„ ë©”íƒ€ ì •ë³´ ê¸°ë°˜ ê²€ìƒ‰
        return self.search_tables_with_graph_metadata(user_request)
    
    def generate_enhanced_prompt(self, user_request: str, relevant_tables: List[str], join_sequence: List[Dict]) -> str:
        """Neo4j ì •ë³´ë¥¼ í™œìš©í•œ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        schema_info = self.generate_schema_prompt()
        
        # ì¡°ì¸ ì •ë³´ ìƒì„±
        join_info = "ìµœì  ì¡°ì¸ ìˆœì„œ ë° ê´€ê³„:\n"
        for i, seq in enumerate(join_sequence):
            table = seq['table']
            joins = seq['joins']
            
            join_info += f"{i+1}. {table}\n"
            for join in joins:
                join_info += f"   â””â”€ {join['from_table']}.{join['from_column']} = {join['to_table']}.{join['to_column']} (ì‹ ë¢°ë„: {join['confidence']})\n"
        
        # ê´€ë ¨ í…Œì´ë¸”ì˜ ìƒì„¸ ì •ë³´
        table_details = "\nê´€ë ¨ í…Œì´ë¸” ìƒì„¸ ì •ë³´:\n"
        for table in relevant_tables:
            if table in self.table_schemas:
                schema = self.table_schemas[table]
                table_details += f"\n{table} í…Œì´ë¸”:\n"
                table_details += f"  ì„¤ëª…: {schema.comment}\n"
                table_details += f"  ì£¼ìš” ì»¬ëŸ¼: {', '.join([col['name'] for col in schema.columns[:5]])}\n"
        
        # LLM íƒ€ì…ê³¼ ëª¨ë¸ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if self.llm_type == "claude":
            # ClaudeëŠ” í•œê¸€ì„ ë§¤ìš° ì˜ ì§€ì›í•˜ë¯€ë¡œ í•œê¸€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = f"""{schema_info}

{join_info}

{table_details}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ ìŠ¤í‚¤ë§ˆì™€ Neo4j ê·¸ë˜í”„ ë¶„ì„ì„ í†µí•œ ìµœì  ì¡°ì¸ ê´€ê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ SELECT SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì œê³µëœ ì¡°ì¸ ìˆœì„œë¥¼ ë”°ë¼ ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì¥í•˜ì„¸ìš”.

ê·œì¹™:
1. ìœ íš¨í•œ SQL ë¬¸ë²• ì‚¬ìš© (MariaDB ê¸°ì¤€)
2. ê¶Œì¥ëœ ì¡°ì¸ ìˆœì„œ ë”°ë¥´ê¸°
3. ì ì ˆí•œ WHERE ì¡°ê±´ í¬í•¨
4. í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸
5. SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ì¶”ê°€ ì„¤ëª… ì—†ì´

SQL ì¿¼ë¦¬:"""
        elif "starcoder" in self.model_name.lower():
            # StarCoderëŠ” ì˜ì–´ ìœ„ì£¼ë¡œ í•™ìŠµë˜ì–´ ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = f"""{schema_info}

{join_info}

{table_details}

User Request: {user_request}

Based on the schema above and the optimal join relationships from Neo4j graph analysis, generate an accurate SELECT SQL query.
Use the join sequence provided to ensure optimal performance.

Rules:
1. Use valid SQL syntax (MariaDB)
2. Follow the recommended join order
3. Include appropriate WHERE conditions
4. Return only the SQL query

SQL Query:"""
        else:
            # ê¸°íƒ€ ëª¨ë¸ë“¤ì€ í•œê¸€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ëŒ€ë¶€ë¶„ í•œê¸€ ì§€ì›)
            prompt = f"""{schema_info}

{join_info}

{table_details}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ ìŠ¤í‚¤ë§ˆì™€ Neo4j ê·¸ë˜í”„ ë¶„ì„ì„ í†µí•œ ìµœì  ì¡°ì¸ ê´€ê³„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ SELECT SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ì œê³µëœ ì¡°ì¸ ìˆœì„œë¥¼ ë”°ë¼ ìµœì ì˜ ì„±ëŠ¥ì„ ë³´ì¥í•˜ì„¸ìš”.

ê·œì¹™:
1. ìœ íš¨í•œ SQL ë¬¸ë²• ì‚¬ìš©
2. ê¶Œì¥ëœ ì¡°ì¸ ìˆœì„œ ë”°ë¥´ê¸°
3. ì ì ˆí•œ WHERE ì¡°ê±´ í¬í•¨
4. SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜

SQL ì¿¼ë¦¬:"""
        
        return prompt
    
    def generate_sql_query(self, user_request: str) -> Optional[str]:
        """ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ SQL ì¿¼ë¦¬ ìƒì„±"""
        schema_info = self.generate_schema_prompt()
        
        # LLM íƒ€ì…ê³¼ ëª¨ë¸ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if self.llm_type == "claude":
            # ClaudeëŠ” í•œê¸€ì„ ë§¤ìš° ì˜ ì§€ì›í•˜ë¯€ë¡œ í•œê¸€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = f"""{schema_info}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” ì •í™•í•œ SELECT SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. ë°˜ë“œì‹œ ìœ íš¨í•œ SQL ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš” (MariaDB ê¸°ì¤€)
2. í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”
3. WHERE ì¡°ê±´ì´ í•„ìš”í•œ ê²½ìš° ì ì ˆíˆ ì¶”ê°€í•˜ì„¸ìš”
4. ê²°ê³¼ëŠ” SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ë¶€ê°€ ì„¤ëª…ì€ ì œì™¸í•˜ì„¸ìš”
5. ì¿¼ë¦¬ëŠ” SELECTë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤

SQL ì¿¼ë¦¬:"""
        elif "starcoder" in self.model_name.lower():
            # StarCoderëŠ” ì˜ì–´ ìœ„ì£¼ë¡œ í•™ìŠµë˜ì–´ ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            prompt = f"""{schema_info}

User Request: {user_request}

Based on the table schema above, generate an accurate SELECT SQL query that meets the user's request.
Please follow these rules:
1. Use valid SQL syntax (MariaDB)
2. Ensure table and column names are correct
3. Add WHERE conditions if needed
4. Return only the SQL query without additional explanations
5. The query must start with SELECT

SQL Query:"""
        else:
            # ê¸°íƒ€ ëª¨ë¸ë“¤ì€ í•œê¸€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ëŒ€ë¶€ë¶„ í•œê¸€ ì§€ì›)
            prompt = f"""{schema_info}

ì‚¬ìš©ì ìš”ì²­: {user_request}

ìœ„ì˜ í…Œì´ë¸” ìŠ¤í‚¤ë§ˆë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ì ìš”ì²­ì— ë§ëŠ” ì •í™•í•œ SELECT SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
ë‹¤ìŒ ê·œì¹™ì„ ë”°ë¼ì£¼ì„¸ìš”:
1. ë°˜ë“œì‹œ ìœ íš¨í•œ SQL ë¬¸ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”
2. í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª…ì´ ì •í™•í•œì§€ í™•ì¸í•˜ì„¸ìš”
3. WHERE ì¡°ê±´ì´ í•„ìš”í•œ ê²½ìš° ì ì ˆíˆ ì¶”ê°€í•˜ì„¸ìš”
4. ê²°ê³¼ëŠ” SQL ì¿¼ë¦¬ë§Œ ë°˜í™˜í•˜ê³  ë¶€ê°€ ì„¤ëª…ì€ ì œì™¸í•˜ì„¸ìš”
5. ì¿¼ë¦¬ëŠ” SELECTë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤

SQL ì¿¼ë¦¬:"""

        print("ğŸ¤– LLMì´ SQL ì¿¼ë¦¬ë¥¼ ìƒì„± ì¤‘...")
        response = self.call_llm(prompt)
        
        if response:
            # SQL ì¿¼ë¦¬ ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ ì œê±° ë“±)
            lines = response.split('\n')
            sql_lines = []
            in_sql = False
            
            for line in lines:
                line = line.strip()
                if line.upper().startswith('SELECT'):
                    in_sql = True
                if in_sql:
                    sql_lines.append(line)
                    if line.endswith(';'):
                        break
            
            if sql_lines:
                sql_query = ' '.join(sql_lines)
                # ì„¸ë¯¸ì½œë¡  ì¶”ê°€
                if not sql_query.endswith(';'):
                    sql_query += ';'
                return sql_query
        
        return None
    
    def execute_query(self, query: str) -> Optional[List[tuple]]:
        """ìƒì„±ëœ SQL ì¿¼ë¦¬ ì‹¤í–‰"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(query)
                results = cursor.fetchall()
                return results
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return None
    
    def run_interactive_mode(self):
        """ëŒ€í™”í˜• ëª¨ë“œ ì‹¤í–‰"""
        print("=" * 70)
        print("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ SQL ì¿¼ë¦¬ ìƒì„±ê¸° ì‹œì‘ (MariaDB + Neo4j)")
        print(f"ğŸ¤– ì‚¬ìš© ì¤‘ì¸ LLM: {self.llm_type.upper()}")
        if self.llm_type == "claude":
            print(f"ğŸ“‹ ëª¨ë¸: {self.claude_model}")
        else:
            print(f"ğŸ“‹ ëª¨ë¸: {self.model_name}")
        print("=" * 70)
        
        # MariaDB ì—°ê²° í™•ì¸
        if not self.connect_to_database():
            return
        
        # LLM ì—°ê²° ë° ëª¨ë¸ í™•ì¸
        if self.llm_type == "ollama":
            if not self.check_ollama_connection():
                return
            
            if not self.check_model_availability():
                print("\nğŸ’¡ OLLAMA ëª¨ë¸ì„ ë¨¼ì € ì„¤ì¹˜í•´ì£¼ì„¸ìš”:")
                print(f"ollama pull {self.model_name}")
                return
        elif self.llm_type == "claude":
            if not self.check_model_availability():
                print("\nğŸ’¡ Claude API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
                print("1. ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •")
                print("2. anthropic ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜: pip install anthropic")
                return
        
        # í…Œì´ë¸” ë¶„ì„
        self.analyze_all_tables()
        
        if not self.tables_info:
            print("âŒ ë¶„ì„í•  í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # Neo4j ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ìƒì„±
        neo4j_available = self.connect_to_neo4j()
        
        if neo4j_available:
            print("\nğŸ”„ ìŠ¤í‚¤ë§ˆ ê·¸ë˜í”„ ë¶„ì„ ì¤‘...")
            self.extract_schema_from_ddl()
            self.extract_table_relations()
            self.create_schema_graph_in_neo4j()
            
            # ì»¬ëŸ¼ ë¶„ì„ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ê°•í™”
            self.enrich_table_metadata_with_column_analysis()
            
            # ì‹¤ì œ ë°ì´í„° ê°’ ë¶„ì„ ê¸°ë°˜ ë©”íƒ€ë°ì´í„° ê°•í™” (ì„¤ëª…ì´ ë¶€ì¡±í•œ í…Œì´ë¸”ë§Œ)
            self.enrich_metadata_with_data_analysis()
            print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ í™œì„±í™”! (Neo4j ê·¸ë˜í”„ ë¶„ì„ + ì»¬ëŸ¼ëª…/ë°ì´í„°ê°’ ê¸°ë°˜ ì—­í•  ì¶”ì • ì‚¬ìš©)")
        else:
            print("âš ï¸  ê¸°ë³¸ ëª¨ë“œë¡œ ì‹¤í–‰ (Neo4j ì—†ì´)")
        
        print("\n" + "=" * 60)
        print("ğŸ¯ ëŒ€í™”í˜• SQL ì¿¼ë¦¬ ìƒì„± ëª¨ë“œ")
        print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        print("=" * 60)
        
        while True:
            try:
                user_input = input("\nğŸ“ ê²€ìƒ‰í•˜ê³  ì‹¶ì€ ë‚´ìš©ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                    break
                
                if not user_input:
                    continue
                
                # SQL ì¿¼ë¦¬ ìƒì„± (í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œ ìš°ì„ )
                if neo4j_available:
                    generated_query = self.generate_hybrid_sql_query(user_input)
                else:
                    generated_query = self.generate_sql_query(user_input)
                
                if generated_query:
                    print(f"\nâœ¨ ìƒì„±ëœ SQL ì¿¼ë¦¬:")
                    print(f"```sql\n{generated_query}\n```")
                    
                    # ì¿¼ë¦¬ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸
                    execute = input("\nì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                    
                    if execute in ['y', 'yes', 'ã…‡']:
                        results = self.execute_query(generated_query)
                        
                        if results is not None:
                            print(f"\nğŸ“Š ì‹¤í–‰ ê²°ê³¼ ({len(results)}ê°œ í–‰):")
                            
                            if results:
                                for i, row in enumerate(results[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í‘œì‹œ
                                    print(f"  {i}: {row}")
                                
                                if len(results) > 10:
                                    print(f"  ... ë° {len(results) - 10}ê°œ í–‰ ë”")
                            else:
                                print("  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            print("âŒ ì¿¼ë¦¬ ì‹¤í–‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                else:
                    print("âŒ SQL ì¿¼ë¦¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        self.disconnect_from_database()
        print("ğŸ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    generator = HybridQueryGenerator()
    generator.run_interactive_mode()

if __name__ == "__main__":
    main()
